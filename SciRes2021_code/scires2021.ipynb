{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.metrics import Precision, Recall, TrueNegatives, TruePositives, FalseNegatives, FalsePositives\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D, Reshape, GlobalAveragePooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# multi-class CNN model take 1\n",
    "# increase filters from 50 to 75\n",
    "filters = 75\n",
    "# decreased kernel size by half\n",
    "kernel_size = 18\n",
    "cnn_1 = Sequential()\n",
    "cnn_1.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(5000, 1)))\n",
    "cnn_1.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "cnn_1.add(MaxPooling1D(3))\n",
    "cnn_1.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "cnn_1.add(Conv1D(filters, kernel_size, activation='relu'))\n",
    "cnn_1.add(GlobalAveragePooling1D())\n",
    "cnn_1.add(Dropout(0.5))\n",
    "cnn_1.add(Dense(activation='softmax', units=1))\n",
    "print(cnn_1.summary())\n",
    "\n",
    "\n",
    "# CNN model performance evaluation\n",
    "callbacks_list = [\n",
    "#    ModelCheckpoint(\n",
    "#        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "#        monitor='val_loss', save_best_only=True),\n",
    "    EarlyStopping(monitor='accuracy', patience=2)\n",
    "]\n",
    "cnn_1.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy', Precision(), Recall(), TrueNegatives(), TruePositives(), FalseNegatives(), FalsePositives(), 'AUC'])\n",
    "\n",
    "history = cnn_1.fit(train_set_pieces,\n",
    "                    train_set_targets,\n",
    "                    batch_size=24,\n",
    "                    epochs=20,\n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_split=0,\n",
    "                    verbose=2)\n",
    "print('Training metrics:', history.history)\n",
    "\n",
    "results = cnn_1.evaluate(\n",
    "    test_set_pieces, test_set_targets, verbose=2, sample_weight=None, return_dict=False)\n",
    "print('Test metrics:', results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4965, 50)          1850      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4930, 50)          90050     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1643, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1608, 50)          90050     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1573, 50)          90050     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 272,051\n",
      "Trainable params: 272,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_set_pieces' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-61514390b3f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 optimizer='adam', metrics=['accuracy', Precision(), Recall(), TrueNegatives(), TruePositives(), FalseNegatives(), FalsePositives(), 'AUC'])\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m history = cnn_1.fit(train_set_pieces,\n\u001b[0m\u001b[1;32m     36\u001b[0m                     \u001b[0mtrain_set_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set_pieces' is not defined"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  },
  "orig_nbformat": 2,
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}